{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deea-c/DeepLearning_GroupProject/blob/main/DL_Assignment_baseline-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xveQIshNWYdc"
      },
      "source": [
        "# Loading Dataset\n",
        "\n",
        "You can download the dataset from {https://darwin.v7labs.com/v7-labs/covid-19-chest-x-ray-dataset?sort=priority\\%3Adesc}.\n",
        "The data entitled as '`darwin dataset pull v7-labs/covid-19-chest-x-ray-dataset:all-images`' will be used in this assignment. All dataset consist of 6504 images from 702 classes. We will extract the images of 4 classes (Bacterial Pneumonia, Viral Pneumonia, No Pneumonia (healthy), Covid-19) and save them as .npy file with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### test "
      ],
      "metadata": {
        "id": "nVpVtkaHw5SJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6bqTVRSs-sw"
      },
      "outputs": [],
      "source": [
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import glob\n",
        "import pandas as pd\n",
        "\n",
        "# importing modules\n",
        "import urllib.request\n",
        "from PIL import Image\n",
        "from keras import layers, models\n",
        "import tensorflow as tf\n",
        "\n",
        "# all-images file should be uploaded to the same file\n",
        "imageNames = glob.glob(\".../all-images/*\")\n",
        "\n",
        "dataset = []\n",
        "labels = []\n",
        "\n",
        "for i, imName in enumerate(imageNames):\n",
        "\n",
        "    # Opening JSON file\n",
        "    f = open(imName)\n",
        "    data = json.load(f)\n",
        "    for j in range(len(data['annotations'])):\n",
        "\n",
        "        if 'COVID-19' in (data['annotations'][j]['name']):\n",
        "          #load images from url    \n",
        "            urllib.request.urlretrieve(data['image']['url'],\"img.png\")    \n",
        "            img = Image.open(\"img.png\")\n",
        "            #convert images to grayscale\n",
        "            imgGray = img.convert('L')\n",
        "            #resize the image (156x156)\n",
        "            im = imgGray.resize((156,156), Image.LANCZOS)           \n",
        "            label = data['annotations'][j]['name']\n",
        "            dataset.append(np.array(im))\n",
        "            labels.append(label)\n",
        "            print(label)\n",
        "            break\n",
        "\n",
        "        if 'Viral Pneumonia' in (data['annotations'][j]['name']) \\\n",
        "            or 'Bacterial Pneumonia' in (data['annotations'][j]['name']) \\\n",
        "            or 'No Pneumonia (healthy)' in (data['annotations'][j]['name']):\n",
        "            #load images from url    \n",
        "            urllib.request.urlretrieve(data['image']['url'],\"img.png\")    \n",
        "            img = Image.open(\"img.png\")\n",
        "            #convert images to grayscale\n",
        "            imgGray = img.convert('L')\n",
        "            #resize the image (156x156)\n",
        "            im = imgGray.resize((156,156), Image.LANCZOS)           \n",
        "            label = data['annotations'][j]['name']\n",
        "            dataset.append(np.array(im))\n",
        "            labels.append(label)\n",
        "            break\n",
        "\n",
        "#Convert data shape of (n_of_samples, width, height, 1)\n",
        "dataset = np.dstack(dataset)    \n",
        "dataset = np.rollaxis(dataset,-1)\n",
        "labels = np.array(labels)\n",
        "\n",
        "#convert images gray scale to rgb\n",
        "data = np.array(layers.Lambda(tf.image.grayscale_to_rgb)(tf.expand_dims(dataset, -1)))\n",
        "\n",
        "# save data and labels into a folder\n",
        "np.save(\".../data.npy\", data)\n",
        "np.save(\".../labels.npy\", labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dn3sH7yJWboe"
      },
      "source": [
        "Once you save your data, you can load it from your directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6ZPDhVLWbyq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.load('.../data.npy')\n",
        "labels = np.load('.../labels.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1b7dP-VbJpC"
      },
      "source": [
        "# Preprocessing Steps\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC_YmdQMbn1K"
      },
      "source": [
        "## Splitting Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xStbdJAHblFv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-r4ta3MbKLJ"
      },
      "source": [
        "## Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeplL77mbKS4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YONVgtOAbKca"
      },
      "source": [
        "# Create Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhUlV9UNbKiH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOFuKRShbvTU"
      },
      "source": [
        "# Analyze the performance of the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58gf79ODcFPD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnxtO6BIb3_P"
      },
      "source": [
        "# Adapting/fine-tuning the network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oiDja0Mub4YW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGr0x8ZcFn9"
      },
      "source": [
        "# Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn_WnCfDcFyD"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}